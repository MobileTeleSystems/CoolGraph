# this config is for NNconv
# using device
# https://pytorch.org/docs/stable/notes/cuda.html
device: cuda:0
targets:
  - label_3
  - label_4
  - label_5
  - label_6
# Number of neighbors are sampled for each node in each iteration (if set -1, -1 - sampling all)
num_neighbors:
  - -1
  - -1
# Numbers of samples per batch to load.
batch_size: 250
# learning rate 
initial_lr: 0.0023
# weight decay (L2 penalty). Using in optimization
weight_decay: 0.0001
# num of epochs per training 
n_epochs: 10
# given stages of the training procedure (grouping epochs)
eval_freq: 5
# metric to maximize
main_metric_name: Auc-total
# Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones.
# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.MultiStepLR.html
scheduler_type: MultiStepLR
scheduler_params:
  milestones:
    - 10
    - 20
    - 35
    - 50
    - 70
    - 90
    - 105
  gamma: 0.25
# This criterion computes the cross entropy loss between input logits and target
loss:
  name: CrossEntropyLoss
  label_smoothing: False
# weights for targets 
  target_weights:
    label_3: 1
    label_4: 1
    label_5: 1
    label_6: 1 
# weights for groups in nodes 
  group_weights:
    - 0.8
    - 1
  fill_value: -100

